{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44fcebc9-5df3-4a7c-b32e-ba80bd1b7b97",
   "metadata": {},
   "source": [
    "### The following is from [HERE](https://geographicdata.science/book/notebooks/11_regression.html), then modified as the example is worked through"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6516b0ae-7b71-47ea-b572-b41a03e6ad48",
   "metadata": {},
   "source": [
    "## Spatial Regression\n",
    "Regression (and predicion more generally), provides us a perfect case to examine how spatial structure can help us inderstand and analyze our data. In this chaprer we discuss how spatial structure can be used to both validate and imprive predicion algorithms, ficusing on linear regression speciffically. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "882b30eb-aa46-4fa5-979b-76c5225a461c",
   "metadata": {},
   "source": [
    "### What is spatial regression and why should I care?\n",
    "\n",
    "Usually, Spatial structure helps regression models in one of two ways, The first (and most clear) way space can have an impact on our data is when the process *generating* the data is itself inherently spatial. Here, thisk of somthing like the prices ofr a single family home. It;s often the case that individuals pay a premiium on their house price in order to live in a better school district for the same quality house. Alternativly, homes closer to noie or chemical polluters like waste watter tretment plants, recycling facilities, or wide highways, may actuallu be cheaper than we would otherwise anticipate. In cases like aethma incidence, the locations individuals tend to travel to throughout the day - such as their work of areas of recreation- mau have more of an impact on their health than their given residential address. In this case, it may be necessary to use the data *from other sites* to predict the asthema incidence at a given site. Regardless of the specific case at play here, *geography is a feature*: it directly helps us make predictions about outcomes *because the outcomes are obtained from a geographical process*\n",
    "\n",
    "An alternative (and more skeptical understanding) reluctantly acknoledged geography's instrumental value. Often, in the analysis of predictive methods and classifiers, we are interested in analyzing what we get wrong. This in common in econometrics; an analyst may be concerned that the model *systematically* mis-predicts somme types of observations. If we know our model routinely performs poorly on a known set of observations or type fo input, we might make a better model if we can account for this. Among other kinds of error diagnostics, geography provides us with an explicitly useful embedding to assess structure in our errors. Mapping classification/prediction error can help us show whether or not there are *clusters of error* in our data. If we *know* that errors tend to be larger in some areas than other areas (or if error is \"contigious\" between observations), then we might be able to exploit this structure to bake better predictions. \n",
    "\n",
    "Spatial structure in our errors might arise from when geography *should be* an attribute somehow, but we are not sure exactally how to include it in our model. THey may also arise because there is some *other* feature whose omission causes the spatial patterns in the error we see. If this additional feature were included, the structure would disapper. Or, it might arise from the complex interactions and interdependencies between the features that we have chosen as predictors., resulting in an intrinsic structure in mis-prediction. Most of the predictors we use in models of social processes contain *embodied* spatial information: patterning ontrinsic to the feature that er get for free in the model. If we intend to or not, using a spatailly patterened predictor in a model can result in spatially patterned errorsl using more thatn one can amplify this effect. Thus, *regardless of whether or not the true preocess is explicitly geographic*, additional information about the spatial relationships between our observations or more information about nearby sites can make our predictions better. \n",
    "\n",
    "In this notebook, we build space into the traditional regression framework. We begin with a standard linear regression model, devoid of andy geographical reference. From there, we formalize space and spatial relationships in three main ways: \n",
    "* encoding it in exogenous variables\n",
    "* through spatial heterogeneity, or as systematic variation of outcomes across space\n",
    "* as dependence, or through the effect associated th the characteristics of spatial neighbors.\n",
    "  \n",
    "Throughout, we focus on the conceptual difffernces each approach entails rather than on the technical details. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a66aa9a6-1d51-4c36-a0ee-e4ec2b47d99a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OMP: Info #276: omp_set_nested routine deprecated, please use omp_set_max_active_levels instead.\n",
      "/home/skye/miniconda3/envs/Spatial_stats/lib/python3.11/site-packages/spaghetti/network.py:42: FutureWarning: The next major release of pysal/spaghetti (2.0.0) will drop support for all ``libpysal.cg`` geometries. This change is a first step in refactoring ``spaghetti`` that is expected to result in dramatically reduced runtimes for network instantiation and operations. Users currently requiring network and point pattern input as ``libpysal.cg`` geometries should prepare for this simply by converting to ``shapely`` geometries.\n",
      "  warnings.warn(dep_msg, FutureWarning, stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "from pysal.lib import weights\n",
    "from pysal.explore import esda\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import contextily"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d3cf9c-fdbd-4e48-b941-d0ba8d616b34",
   "metadata": {},
   "source": [
    "### Data: San Diego Airbnb\n",
    "\n",
    "To learn a little about how regressoin works, we'll examine information about Airbnb properties in San Diego, CA. THis dataset contains house intrinsic charateristics, both continious (number of beds as in beds) and categorical (type of renting, of, in Airbnb jargon, property group as in the series of pg_X binary variables), but also variables that explicitly refer to the location and spatial configuration of the dataset (e.g., distance to Balboa Park, d2balboa or neighborhood id, neighborhood_cleansed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b940b63f-3ceb-4d3c-ab72-2c93bd0f8757",
   "metadata": {},
   "outputs": [],
   "source": [
    "db = gpd.read_file(\"../data/air_bnb/regression_db.geojson\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69cfff02-1ba5-49c1-9399-c4fdafa868c5",
   "metadata": {},
   "source": [
    "These are the explanatory variables we will use throughout the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d40e0a2-f53e-4e4d-adb2-ee6149d13c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "variable_names = [\n",
    "    \"accommodates\",  # Number of people it accommodates\n",
    "    \"bathrooms\",  # Number of bathrooms\n",
    "    \"bedrooms\",  # Number of bedrooms\n",
    "    \"beds\",  # Number of beds\n",
    "    # Below are binary variables, 1 True, 0 False\n",
    "    \"rt_Private_room\",  # Room type: private room\n",
    "    \"rt_Shared_room\",  # Room type: shared room\n",
    "    \"pg_Condominium\",  # Property group: condo\n",
    "    \"pg_House\",  # Property group: house\n",
    "    \"pg_Other\",  # Property group: other\n",
    "    \"pg_Townhouse\",  # Property group: townhouse\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "129c946f-f77a-4678-8096-0eceb0419a9b",
   "metadata": {},
   "source": [
    "### Non-Spatial Regression, A (Very) Quick Refresh\n",
    "\n",
    "Before we discuss how to explicitly include space into the linear regression framework, lwt us show how basic regression can be carried out in Python, and how on can begin to interperate the results. By no means is this a formal and complete introduction to regtrsion, so if that is what you are looking for see [GH06](https://doi.org/10.1017/cbo9780511790942) (in particular chapters 3 and 4, which provide a fantastic, non-spatial introduction).\n",
    "\n",
    "The core idea of linear regression is to explain the variation in a given (*dependent*) variable as a linear function fo a collection of other (*explanatory*) variables. For example, in our case, we may want to express the price of a house as a finction of the number of bedroome it has and whether it is a condominium or not. At the individual level, we express this as:\n",
    "\n",
    "$P_i = \\alpha + \\sum\\limits_{k}\\bf{X}_{ik}\\beta_k + \\epsilon_{i}$\n",
    "\n",
    "where $P_i$ in the Airbnb price of house $i$ and $\\bf{X}$ is a set of covariates that we use to explain such price (e.g., No. of bedrooms and condominium binary variable). $\\beta$ is a vector of parameters that give us information about in which way (e.g., increases price, decreases) and to what extent (e.g., var_a is responsible for 20% of price), $\\alpha$ is a constant term that explains the average price of a house with all other variable set to zero. The term $\\epsilon_{i}$ is an error term and captures elemente that influence the price of a house not included in $\\bf{X}$, We can also express this relation in matrix form, excluding sub-indicies for $i$, which yields:\n",
    "\n",
    "$P = \\alpha + \\bf{X}\\beta + \\epsilon$\n",
    "\n",
    "A regression can be seen as a multivariate extention fo bivariate cerrelations. Indeed one way to interpreate the $\\beta_{k}$ coefficents in the equation above is as the degree of correlation between the explanatory variable $k$ and the dependent variable, *keeping all the other explanatory variables constant*. Whrn one calculates bivatiate correlations, the coefficent of a variable is picling up the forrelation between the variables, but it is also subsuming into it the variation associates eith other correlated variables - also called confounding factors. Regression allows us to isolate the distinct effect that a single variable can have on the dependent one, once we *control* for those other variables. \n",
    "\n",
    "Practically speaking, linear regressions in Python are rather streamlined and easy to work with. There are also several packages which will run them (e.g., statsmodels, scikit-learn, pysal). We will import the spreg module in Pysal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c3d5345-2fbd-4d0f-8f80-903ed6b9a4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pysal.model import spreg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "924bd4ad-f07c-4775-89bf-193b66b8852a",
   "metadata": {},
   "source": [
    "In the context of this notebook it makes sense to start with spreg, as that is the only library that will allow us to move into explicitly spatial econometric models. To fit the model specified in the equation above with $\\bf{X}$ as the list defined, using ordinary least squares (OLS), we need only the following lien of code: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d23062f7-cee2-4a05-8cc9-49243e903e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the OLS model\n",
    "m1 = spreg.OLS(\n",
    "               db[[\"log_price\"]].values,   # Dependent variable\n",
    "               db[variable_names].values,  # Independent variables\n",
    "               name_y=\"log_price\",         # Dependent variable name\n",
    "               name_x=variable_names,      # Independent variable names\n",
    "              )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d875951e-2779-4b5b-95a2-df203ea59541",
   "metadata": {},
   "source": [
    "We use the command OLS, part of the spreg sub-package, and specify the dependent variable (the log of the price, so we can interpret results in terms of percentage change) and the explanatory iones. Note that both objects need to be arrays, we we extract them from the pandas dataframe object with .values.\n",
    "\n",
    "In order to inspect the results of the model, we print the summary attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5658ecd8-071c-460d-ad47-346183f1cac2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REGRESSION RESULTS\n",
      "------------------\n",
      "\n",
      "SUMMARY OF OUTPUT: ORDINARY LEAST SQUARES\n",
      "-----------------------------------------\n",
      "Data set            :     unknown\n",
      "Weights matrix      :        None\n",
      "Dependent Variable  :   log_price                Number of Observations:        6110\n",
      "Mean dependent var  :      4.9958                Number of Variables   :          11\n",
      "S.D. dependent var  :      0.8072                Degrees of Freedom    :        6099\n",
      "R-squared           :      0.6683\n",
      "Adjusted R-squared  :      0.6678\n",
      "Sum squared residual:     1320.15                F-statistic           :   1229.0564\n",
      "Sigma-square        :       0.216                Prob(F-statistic)     :           0\n",
      "S.E. of regression  :       0.465                Log likelihood        :   -3988.895\n",
      "Sigma-square ML     :       0.216                Akaike info criterion :    7999.790\n",
      "S.E of regression ML:      0.4648                Schwarz criterion     :    8073.685\n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "            Variable     Coefficient       Std.Error     t-Statistic     Probability\n",
      "------------------------------------------------------------------------------------\n",
      "            CONSTANT         4.38838         0.01611       272.32178         0.00000\n",
      "        accommodates         0.08345         0.00508        16.43363         0.00000\n",
      "           bathrooms         0.19238         0.01097        17.54198         0.00000\n",
      "            bedrooms         0.15252         0.01113        13.70092         0.00000\n",
      "                beds        -0.04172         0.00694        -6.01344         0.00000\n",
      "     rt_Private_room        -0.55069         0.01590       -34.62448         0.00000\n",
      "      rt_Shared_room        -1.23831         0.03843       -32.21990         0.00000\n",
      "      pg_Condominium         0.14363         0.02215         6.48465         0.00000\n",
      "            pg_House        -0.01049         0.01453        -0.72184         0.47042\n",
      "            pg_Other         0.14115         0.02280         6.19056         0.00000\n",
      "        pg_Townhouse        -0.04167         0.03428        -1.21573         0.22413\n",
      "------------------------------------------------------------------------------------\n",
      "\n",
      "REGRESSION DIAGNOSTICS\n",
      "MULTICOLLINEARITY CONDITION NUMBER           11.964\n",
      "\n",
      "TEST ON NORMALITY OF ERRORS\n",
      "TEST                             DF        VALUE           PROB\n",
      "Jarque-Bera                       2        2671.611           0.0000\n",
      "\n",
      "DIAGNOSTICS FOR HETEROSKEDASTICITY\n",
      "RANDOM COEFFICIENTS\n",
      "TEST                             DF        VALUE           PROB\n",
      "Breusch-Pagan test               10         322.532           0.0000\n",
      "Koenker-Bassett test             10         135.581           0.0000\n",
      "================================ END OF REPORT =====================================\n"
     ]
    }
   ],
   "source": [
    "print(m1.summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ed24f1-fd7f-494e-800f-a317b4abf0b9",
   "metadata": {},
   "source": [
    "A full detailed explanation of the output is beyond the scope of this notebook, so we ficus on the televant bits for our main purpose. The focus will be on the Coefficente section, which gives us the estimates for $\\beta_{k}$ in our model. In other words, these numbners express the relationship between each explanatory variable and the dependent one, once the effict of confounding variables has been accounted for. Keep in mind that regression is no magic; we are only dicounting the effect of confounding factors that we include in the model, not of *all* potintially confounding factors.\n",
    "\n",
    "Results are largely ase expected: houses tend to be significantaly more expensive if they accomodate morte people (variable accomodates), if they have more bathrooms and bedrooms, and if they are a condominium or part of the \"other\" category of house type. Conversly, given a number of rooms, houses with more beds (i.e., listings that are more \"crowded\") tend to go for cheaper, as it is the case for properties where one does not rent the entire house but only a room (variable rt_Private_room) or even shares it (variable rt_Shared_room). Of course, you might conceptually doubt the assumption that it is possible to *arbitrarily* change the number of beds within an Airbnb without eventually changing the number of people it accomodates, but methods to address these concerns using *interaction effects* won't be discussed here. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
